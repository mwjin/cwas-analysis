{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all bed files for annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import yaml\n",
    "import gzip\n",
    "import pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path settings\n",
    "project_dir = os.path.abspath('..')\n",
    "annot_conf_path = os.path.join(project_dir, 'conf', 'annotation.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the configuration\n",
    "with open(annot_conf_path) as annot_conf_file:\n",
    "    annot_path_dict = yaml.safe_load(annot_conf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of bed files\n",
    "merge_bed_path = os.path.join(annot_path_dict['data_dir'], 'merge_track.bed')\n",
    "bed_keys = []\n",
    "\n",
    "for annot_key in annot_path_dict:\n",
    "    annot_path = annot_path_dict[annot_key]\n",
    "    \n",
    "    if annot_path.endswith('bed') or annot_path.endswith('bed.gz'):\n",
    "        bed_keys.append(annot_key)\n",
    "        \n",
    "bed_keys = np.array(bed_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse bed files\n",
    "chroms = [f'chr{n}' for n in range(1, 23)]\n",
    "start_pos_dict = {chrom: {} for chrom in chroms}\n",
    "end_pos_dict = {chrom: {} for chrom in chroms}\n",
    "pos_list_dict = {chrom: [] for chrom in chroms}\n",
    "\n",
    "for i, bed_key in enumerate(bed_keys):\n",
    "    bed_path = annot_path_dict[bed_key]\n",
    "    bed_file = gzip.open(bed_path, 'rt') if bed_path.endswith('gz') else open(bed_file, 'r')\n",
    "    \n",
    "    for line in bed_file.readlines():\n",
    "        fields = line.split('\\t')\n",
    "        chrom = fields[0]\n",
    "        start = int(fields[1])\n",
    "        end = int(fields[2])\n",
    "        \n",
    "        if start_pos_dict.get(chrom) is None:\n",
    "            continue\n",
    "            \n",
    "        # Init\n",
    "        if start_pos_dict[chrom].get(start) is None:\n",
    "            start_pos_dict[chrom][start] = []\n",
    "        \n",
    "        if end_pos_dict[chrom].get(end) is None:\n",
    "            end_pos_dict[chrom][end] = []\n",
    "            \n",
    "        start_pos_dict[chrom][start].append(i)\n",
    "        end_pos_dict[chrom][end].append(i)\n",
    "        pos_list_dict[chrom].append(start)\n",
    "        pos_list_dict[chrom].append(end)\n",
    "        \n",
    "    bed_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_to_int(one_hot):\n",
    "    n = 0\n",
    "    \n",
    "    for i in range(len(one_hot)):\n",
    "        if one_hot[i]:\n",
    "            n += 2 ** i\n",
    "    \n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_one_hot(n, one_hot_len):\n",
    "    one_hot = np.zeros(one_hot_len)\n",
    "    \n",
    "    for i in range(one_hot_len):\n",
    "        bit = n % 2\n",
    "        one_hot[i] += bit\n",
    "        n >>= 1\n",
    "        \n",
    "        if n == 0:\n",
    "            break\n",
    "            \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the beds and make new ones\n",
    "bed_entries = []\n",
    "\n",
    "for chrom in chroms:\n",
    "    pos_list = pos_list_dict[chrom]\n",
    "    pos_list.sort()\n",
    "    start_to_key_idx = start_pos_dict[chrom]\n",
    "    end_to_key_idx = end_pos_dict[chrom]\n",
    "    one_hot = np.zeros(len(bed_keys))\n",
    "    \n",
    "    prev_pos = -1\n",
    "    n_bed = 0\n",
    "    \n",
    "    for pos in pos_list:\n",
    "        if n_bed > 0 and prev_pos != pos:\n",
    "            annot_int = one_hot_to_int(one_hot)\n",
    "            bed_entry = (chrom, prev_pos, pos, annot_int)\n",
    "            bed_entries.append(bed_entry)\n",
    "            n_bed -= 1\n",
    "        \n",
    "        key_idx = end_to_key_idx.get(pos)\n",
    "        \n",
    "        if prev_pos == pos or key_idx is None:  # This position is a start position.\n",
    "            key_idx = start_to_key_idx.get(pos)\n",
    "            one_hot[key_idx] = 1\n",
    "            n_bed += 1\n",
    "        else:\n",
    "            one_hot[key_idx] = 0\n",
    "            \n",
    "        prev_pos = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a bed file\n",
    "with open(merge_bed_path, 'w') as outfile:\n",
    "    bed_key_str = '|'.join(bed_keys)\n",
    "    print(f'#CSQ={bed_key_str}', file=outfile)\n",
    "    print('#chrom', 'start', 'end', 'annot_int', sep='\\t', file=outfile)\n",
    "    \n",
    "    for bed_entry in bed_entries:\n",
    "        print(*bed_entry, sep='\\t', file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_bed(chrom):\n",
    "    # Parse bed files\n",
    "    # Tabix version\n",
    "    merge_bed_path = os.path.join(annot_path_dict['data_dir'], f'merge_track.{chrom}.bed')\n",
    "    start_to_key_idx = {}\n",
    "    end_to_key_idx = {}\n",
    "    pos_list = []\n",
    "\n",
    "    # Read bed entries from each annotation bed file\n",
    "    for i, bed_key in enumerate(bed_keys):\n",
    "        bed_path = annot_path_dict[bed_key]\n",
    "        with pysam.TabixFile(bed_path) as bed_file:\n",
    "\n",
    "            for fields in bed_file.fetch(chrom, parser=pysam.asTuple()):\n",
    "                start = int(fields[1])\n",
    "                end = int(fields[2])\n",
    "\n",
    "                # Init\n",
    "                if start_to_key_idx.get(start) is None:\n",
    "                    start_to_key_idx[start] = []\n",
    "\n",
    "                if end_to_key_idx.get(end) is None:\n",
    "                    end_to_key_idx[end] = []\n",
    "\n",
    "                start_to_key_idx[start].append(i)\n",
    "                end_to_key_idx[end].append(i)\n",
    "                pos_list.append(start)\n",
    "                pos_list.append(end)\n",
    "\n",
    "    # Make new bed file\n",
    "    pos_list.sort()\n",
    "    one_hot = np.zeros(len(bed_keys))\n",
    "    prev_pos = -1\n",
    "    n_bed = 0\n",
    "\n",
    "    with open(merge_bed_path, 'w') as outfile:\n",
    "        for pos in pos_list:\n",
    "            if n_bed > 0 and prev_pos != pos:\n",
    "                annot_int = one_hot_to_int(one_hot)\n",
    "                bed_entry = (chrom, prev_pos, pos, annot_int)\n",
    "                print(*bed_entry, sep='\\t', file=outfile)\n",
    "                n_bed -= 1\n",
    "\n",
    "            key_idx = end_to_key_idx.get(pos)\n",
    "\n",
    "            if prev_pos == pos or key_idx is None:  # This position is a start position.\n",
    "                key_idx = start_to_key_idx.get(pos)\n",
    "                one_hot[key_idx] = 1\n",
    "                n_bed += 1\n",
    "            else:\n",
    "                one_hot[key_idx] = 0\n",
    "\n",
    "            prev_pos = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_curr_time() -> str:\n",
    "    now = datetime.now()\n",
    "    curr_time = now.strftime('%H:%M:%S %m/%d/%y')\n",
    "    return curr_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroms = [f'chr{n}' for n in range(1, 23)]\n",
    "for chrom in chroms:\n",
    "    print(f'[{get_curr_time()}, Progress] {chrom}')\n",
    "    make_new_bed(chrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a bed file\n",
    "new_bed_path = os.path.join(annot_path_dict['data_dir'], f'merge_track.2.bed')\n",
    "\n",
    "with open(new_bed_path, 'w') as outfile:\n",
    "    bed_key_str = '|'.join(bed_keys)\n",
    "    print(f'#CSQ={bed_key_str}', file=outfile)\n",
    "    print('#chrom', 'start', 'end', 'annot_int', sep='\\t', file=outfile)\n",
    "\n",
    "# Append a bed file of each chromosome\n",
    "for chrom in chroms:\n",
    "    print(f'[{get_curr_time()}, Progress] {chrom}')\n",
    "    chr_new_bed_path = new_bed_path.replace('.2.bed', f'.{chrom}.bed')\n",
    "    cmd = f'cat {chr_new_bed_path} >> {new_bed_path}'\n",
    "    os.system(cmd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_and_index(bed_file_path):\n",
    "    cmd = f'bgzip {bed_file_path};'\n",
    "    cmd += f'tabix {bed_file_path + \".gz\"};'\n",
    "    print(cmd)\n",
    "    return os.system(bed_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_and_index(new_bed_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "bio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
